{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "46a2b18c",
   "metadata": {},
   "source": [
    "# Data Cleaning "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad1c7e1f",
   "metadata": {},
   "source": [
    "## Objectives\n",
    "- Clean dataset in preparation for analysis and modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d9bdf7e",
   "metadata": {},
   "source": [
    "## Inputs \n",
    "- outputs/datasets/collection/HousingPrices.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fa15ac4",
   "metadata": {},
   "source": [
    "## Outputs\n",
    "- outputs/datasets/cleaned/HousingPrices.csv\n",
    "- outputs/datasets/cleaned/Test.csv\n",
    "- outputs/datasets/cleaned/Train.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e2e8841",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c25c7603",
   "metadata": {},
   "source": [
    "## Change working directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c434d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "cwd = os.getcwd()\n",
    "cwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1de6c3ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(os.path.dirname(cwd))\n",
    "print(\"You set a new current working directory\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95acb6f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "cwd = os.getcwd()\n",
    "cwd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "989cf20e",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf53bcb1",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dab1eb58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"outputs/datasets/collection/HousingPrices.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62360064",
   "metadata": {},
   "source": [
    "## Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94892d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "vars_with_missing_data = df.columns[df.isna().sum() > 0].to_list()\n",
    "vars_with_missing_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0778eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ydata_profiling import ProfileReport\n",
    "if vars_with_missing_data:\n",
    "    profile = ProfileReport(df=df[vars_with_missing_data], minimal=True)\n",
    "    profile.to_notebook_iframe()\n",
    "else:\n",
    "    print(\"There are no variables with missing data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e791144",
   "metadata": {},
   "source": [
    "## Assessing Missing Data Levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c00ba84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def EvaluateMissingData(df):\n",
    "    missing_data_absolute = df.isnull().sum()\n",
    "    missing_data_percentage = round(missing_data_absolute/len(df)*100, 2)\n",
    "    df_missing_data = (pd.DataFrame(\n",
    "                            data={\"RowsWithMissingData\": missing_data_absolute,\n",
    "                                   \"PercentageOfDataset\": missing_data_percentage,\n",
    "                                   \"DataType\": df.dtypes}\n",
    "                                    )\n",
    "                          .sort_values(by=['PercentageOfDataset'], ascending=False)\n",
    "                          .query(\"PercentageOfDataset > 0\")\n",
    "                          )\n",
    "\n",
    "    return df_missing_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf5954ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "EvaluateMissingData(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdc8b4b0",
   "metadata": {},
   "source": [
    "Observations:\n",
    "- EnclosedPorch and WoodDeckSF have severe levels of missing data. It would be most sensible to drop these fields before any analysis or modelling. \n",
    "- Categorical variables with missing data are GarageFinish, BsmtFinType1 and BsmtExposure - we should use a CategoricalImputer for these variables.\n",
    "- Numerical variables with missing data are LotFrontage, BedroomAbvGr, 2ndFlrSF, GarageAge and MasVnrArea - we should use a MeanMedianImputer or ArbitraryNumberImputer for these variables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "805bf691",
   "metadata": {},
   "source": [
    "### Assessing which imputer to use on numerical values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54bb7265",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22c72337",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "numerical_variables_missing = ['LotFrontage', 'BedroomAbvGr', '2ndFlrSF', 'GarageAge', 'MasVnrArea']\n",
    "\n",
    "for i in numerical_variables_missing:\n",
    "    sns.histplot(df[i].dropna(), kde=True)\n",
    "    plt.title(f\"Distribution of {i}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d038ccb9",
   "metadata": {},
   "source": [
    "Observations: \n",
    "- 2ndFlrSF and GarageAge can be filled with 0. This will be more meaningful than filling with the median, since it likely represents the lack of 2nd floor/garage.\n",
    "- It is likely the missing values for LotFrontage, BedroomAbvGr and MasVnrArea are due to data entry missing, rather than the value is 0, so a MeanMedianImputer works best. We will use a median imputer since these variables are not normally distributed. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed8efe2b",
   "metadata": {},
   "source": [
    "## Handling missing data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e829e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from feature_engine.imputation import MeanMedianImputer, ArbitraryNumberImputer, CategoricalImputer\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a60cd4c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_drop = ['WoodDeckSF', 'EnclosedPorch']\n",
    "\n",
    "def drop_columns(X):\n",
    "    return X.drop(columns=cols_to_drop)\n",
    "\n",
    "dropper = FunctionTransformer(drop_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a88b9bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "      ('drop_cols', dropper),\n",
    "      ( 'median',  MeanMedianImputer(imputation_method='median',\n",
    "                                     variables=['LotFrontage', 'BedroomAbvGr', 'MasVnrArea']) ),\n",
    "      ( 'zero_variables',  ArbitraryNumberImputer(arbitrary_number=-0,\n",
    "                                                  variables=['2ndFlrSF', 'GarageAge']) ),\n",
    "      ( 'cat_imputer',  CategoricalImputer(imputation_method='missing',\n",
    "                                          variables=['GarageFinish', 'BsmtFinType1', 'BsmtExposure']) )\n",
    "])\n",
    "pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08af2989",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.fit(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eae7215",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean = pipeline.transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b77e2e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d3795f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Imputer dict for median: \", pipeline['median'].imputer_dict_)\n",
    "print(\"Imputer dict for zero variables: \", pipeline['zero_variables'].imputer_dict_)\n",
    "print(\"Imputer dict for categorical variables: \", pipeline['cat_imputer'].imputer_dict_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d532f6c0",
   "metadata": {},
   "source": [
    "Observations:\n",
    "- MasVnrArea median is 0 anyway\n",
    "- Other variables are being transformed correctly"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73916c95",
   "metadata": {},
   "source": [
    "## Investigating effect of data cleaning pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef40fdbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.set(style=\"whitegrid\")\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def DataCleaningEffect(df_original,df_cleaned,variables_applied_with_method):\n",
    "\n",
    "  flag_count=1 # Indicate plot number\n",
    "  \n",
    "  # distinguish between numerical and categorical variables\n",
    "  categorical_variables = df_original.select_dtypes(exclude=['number']).columns \n",
    "\n",
    "  # scan over variables, \n",
    "    # first on variables that you applied the method\n",
    "    # if the variable is a numerical plot, a histogram if categorical plot a barplot\n",
    "  for set_of_variables in [variables_applied_with_method]:\n",
    "    print(\"\\n=====================================================================================\")\n",
    "    print(f\"* Distribution Effect Analysis After Data Cleaning Method in the following variables:\")\n",
    "    print(f\"{set_of_variables} \\n\\n\")\n",
    "  \n",
    "\n",
    "    for var in set_of_variables:\n",
    "      if var in categorical_variables:  # it is categorical variable: barplot\n",
    "        \n",
    "        df1 = pd.DataFrame({\"Type\":\"Original\",\"Value\":df_original[var]})\n",
    "        df2 = pd.DataFrame({\"Type\":\"Cleaned\",\"Value\":df_cleaned[var]})\n",
    "        dfAux = pd.concat([df1, df2], axis=0)\n",
    "        fig , axes = plt.subplots(figsize=(15, 5))\n",
    "        sns.countplot(hue='Type', data=dfAux, x=\"Value\",palette=['#432371',\"#FAAE7B\"])\n",
    "        axes.set(title=f\"Distribution Plot {flag_count}: {var}\")\n",
    "        plt.xticks(rotation=90)\n",
    "        plt.legend() \n",
    "\n",
    "      else: # it is numerical variable: histogram\n",
    "\n",
    "        fig , axes = plt.subplots(figsize=(10, 5))\n",
    "        sns.histplot(data=df_original, x=var, color=\"#432371\", label='Original', kde=True,element=\"step\", ax=axes)\n",
    "        sns.histplot(data=df_cleaned, x=var, color=\"#FAAE7B\", label='Cleaned', kde=True,element=\"step\", ax=axes)\n",
    "        axes.set(title=f\"Distribution Plot {flag_count}: {var}\")\n",
    "        plt.legend() \n",
    "\n",
    "      plt.show()\n",
    "      flag_count+= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45879192",
   "metadata": {},
   "outputs": [],
   "source": [
    "DataCleaningEffect(df_original=df,\n",
    "                   df_cleaned=df_clean,\n",
    "                   variables_applied_with_method=numerical_variables_missing)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49feea66",
   "metadata": {},
   "source": [
    "## Splitting cleaned df into test and train sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f554d26f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df_clean\n",
    "y = df_clean['SalePrice']\n",
    "\n",
    "X_train, X_test, y_train, y_test= train_test_split(\n",
    "                                        X,\n",
    "                                        y,\n",
    "                                        test_size=0.2,\n",
    "                                        random_state=0)\n",
    "\n",
    "print(f\"TrainSet shape: {X_train.shape} \\nTestSet shape: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f3bd64f",
   "metadata": {},
   "source": [
    "### Checking train set is clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0015af68",
   "metadata": {},
   "outputs": [],
   "source": [
    "EvaluateMissingData(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcde6178",
   "metadata": {},
   "source": [
    "## Push cleaned data to repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65e39736",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "out_dir = Path(\"outputs/datasets/cleaned\")\n",
    "out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "df_clean.to_csv(out_dir / \"HousingPrices.csv\", index=False)\n",
    "X_train.to_csv(out_dir / \"TrainSetCleaned.csv\", index=False)\n",
    "X_test.to_csv(out_dir / \"TestSetCleaned.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "221b850d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
